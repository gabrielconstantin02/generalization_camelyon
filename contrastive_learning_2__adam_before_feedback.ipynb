{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "collapsed": true,
        "id": "iwSgBXS4WnPJ"
      },
      "outputs": [],
      "source": [
        "# !pip install wilds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from wilds import get_dataset\n",
        "from wilds.common.data_loaders import get_train_loader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from wilds.common.data_loaders import get_eval_loader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fbFdMbP_WnPK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "outputs": [],
      "source": [
        "# Load the full dataset, and download it if necessary\n",
        "dataset = get_dataset(dataset=\"camelyon17\", download=False)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bAbxogzDWnPL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99804\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Train loop\\nfor labeled_batch, unlabeled_batch in zip(train_loader, unlabeled_loader):\\n    x, y, metadata = labeled_batch\\n    unlabeled_x, unlabeled_metadata = unlabeled_batch\\n    ...\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "FRACTION = 0.33\n",
        "\n",
        "# Get the training set\n",
        "train_data = dataset.get_subset(\n",
        "    \"train\",\n",
        "    frac = FRACTION,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(len(train_data)) #302436 initially\n",
        "\n",
        "\"\"\"\n",
        "# (Optional) Load unlabeled data\n",
        "dataset = get_dataset(dataset=\"camelyon17\", download=True, unlabeled=True)\n",
        "unlabeled_data = dataset.get_subset(\n",
        "    \"test_unlabeled\",\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
        "    ),\n",
        ")\n",
        "unlabeled_loader = get_train_loader(\"standard\", unlabeled_data, batch_size=16)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "# Train loop\n",
        "for labeled_batch, unlabeled_batch in zip(train_loader, unlabeled_loader):\n",
        "    x, y, metadata = labeled_batch\n",
        "    unlabeled_x, unlabeled_metadata = unlabeled_batch\n",
        "    ...\n",
        "\"\"\""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "vkrWsMbmWnPL",
        "outputId": "875a9ab5-5ab1-41cb-dc11-065624b07697"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11075\n"
          ]
        }
      ],
      "source": [
        "# Get the id_val set\n",
        "id_val_data = dataset.get_subset(\n",
        "    \"id_val\",\n",
        "    frac = FRACTION,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(len(id_val_data))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bQG8UEhWnPM",
        "outputId": "eb80d900-1ab2-4298-e6c7-9f85f7d3aeef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11518\n"
          ]
        }
      ],
      "source": [
        "# Get the val set\n",
        "val_data = dataset.get_subset(\n",
        "    \"val\",\n",
        "    frac = FRACTION,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(len(val_data))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84YtJhH4WnPM",
        "outputId": "edd77ded-613b-4519-9246-09c85f504aba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28068\n"
          ]
        }
      ],
      "source": [
        "# Get the test set\n",
        "test_data = dataset.get_subset(\n",
        "    \"test\",\n",
        "    frac = FRACTION,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(len(test_data))\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD1XSgxnWnPN",
        "outputId": "8e244c21-dfb1-4851-a4d4-de6b5628c515"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBsZzsWSBO2G",
        "outputId": "79a69aef-a709-4055-93bd-3020dc1748c2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[ 1.1358,  0.9474,  0.9132,  ..., -0.3369,  0.7762,  0.0741],\n",
            "         [ 1.2043,  0.9646,  0.8961,  ...,  1.5982,  1.6324,  0.7933],\n",
            "         [ 1.1872,  0.9303,  0.9303,  ...,  1.4783,  1.3755,  1.1358],\n",
            "         ...,\n",
            "         [-0.3541,  0.1426,  1.1187,  ...,  1.4269,  0.3994, -0.3541],\n",
            "         [-0.7479, -0.5082,  0.4851,  ...,  1.1700, -0.3883, -0.8849],\n",
            "         [-0.8849, -0.5938,  0.4337,  ...,  0.8961, -0.5596, -0.4397]],\n",
            "\n",
            "        [[ 0.3277,  0.1001,  0.0651,  ..., -0.5301, -0.0924, -0.3200],\n",
            "         [ 0.3102,  0.0826,  0.0826,  ...,  1.4657,  1.7108,  0.7829],\n",
            "         [ 0.0301, -0.1450, -0.0224,  ...,  0.6779,  1.0455,  0.3277],\n",
            "         ...,\n",
            "         [-1.1078, -0.5826,  0.3452,  ...,  1.1331,  0.0826, -0.8452],\n",
            "         [-1.2129, -0.8978, -0.3025,  ...,  1.0280, -0.5476, -1.0903],\n",
            "         [-0.9853, -1.2479, -0.4951,  ...,  0.8704, -0.8452, -0.9503]],\n",
            "\n",
            "        [[ 1.8383,  1.6988,  1.5594,  ...,  1.0365,  1.6988,  1.0714],\n",
            "         [ 1.8208,  1.7163,  1.6291,  ...,  2.3786,  2.3611,  1.9254],\n",
            "         [ 1.6117,  1.5768,  1.5594,  ...,  1.9777,  1.9254,  1.7685],\n",
            "         ...,\n",
            "         [ 0.7925,  1.2457,  2.0997,  ...,  2.0125,  1.2108,  0.7228],\n",
            "         [ 0.5311,  0.8099,  1.7163,  ...,  1.9603,  1.0365,  0.7228],\n",
            "         [ 0.8099,  0.7925,  1.5420,  ...,  1.6814,  0.8971,  0.9668]]]), tensor(1), tensor([ 2, 20,  1,  0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh8tjoQVC93N",
        "outputId": "722fbec5-05ed-44a1-9862-566c21ecd3b7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[ 0.2111,  0.6049,  1.5125,  ...,  0.9303,  1.0673,  0.4337],\n",
            "         [ 0.2111,  0.1597,  0.5193,  ...,  1.1872,  1.2899, -0.1828],\n",
            "         [ 0.2453,  0.1426,  0.2796,  ...,  1.6324,  1.2557,  0.2282],\n",
            "         ...,\n",
            "         [ 1.0673,  0.3138,  0.6906,  ...,  0.8276,  0.7762,  0.5707],\n",
            "         [ 1.7865,  0.4679,  0.5878,  ...,  0.4851,  0.5536,  0.6563],\n",
            "         [ 1.2214,  0.8447,  1.1700,  ...,  0.6221,  0.6392,  0.6049]],\n",
            "\n",
            "        [[-0.8627, -0.1800,  1.1155,  ...,  0.3452,  0.5028, -0.1800],\n",
            "         [-0.7402, -0.8277, -0.2500,  ...,  0.7304,  0.6954, -0.9678],\n",
            "         [-0.5826, -0.8803, -0.5826,  ...,  1.3256,  0.7479, -0.4951],\n",
            "         ...,\n",
            "         [ 0.5903, -0.3375, -0.0924,  ...,  0.0126, -0.0049, -0.2325],\n",
            "         [ 1.5182, -0.0574, -0.1275,  ..., -0.3550, -0.3375, -0.2325],\n",
            "         [ 0.8704,  0.3452,  0.5903,  ..., -0.2325, -0.1800, -0.2325]],\n",
            "\n",
            "        [[ 0.1302,  0.5485,  1.6465,  ...,  1.0191,  1.4374,  0.7751],\n",
            "         [ 0.2522,  0.0779,  0.4265,  ...,  1.0888,  1.3154,  0.0431],\n",
            "         [ 0.4614,  0.2173,  0.2348,  ...,  2.0125,  1.6640,  0.1651],\n",
            "         ...,\n",
            "         [ 1.2980,  0.5834,  0.6705,  ...,  0.8622,  0.7751,  0.5834],\n",
            "         [ 2.1171,  0.6531,  0.7576,  ...,  0.5659,  0.6531,  0.8099],\n",
            "         [ 1.5071,  0.9494,  1.4722,  ...,  0.6182,  0.7054,  0.7402]]]), tensor(1), tensor([ 1, 10,  1,  0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_val_data = []\n",
        "for idx in range(len(val_data)):\n",
        "  transformed_val_data.append((val_data[idx][0], torch.tensor(2) if val_data[idx][1].item() == 0 else torch.tensor(3), val_data[idx][2]))"
      ],
      "metadata": {
        "id": "ovqRw48QBxQT"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transformed_val_data[0])"
      ],
      "metadata": {
        "id": "BqtKW-3OC6a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f40663-7850-43ff-8d11-ebd8bd7605a0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[ 0.2111,  0.6049,  1.5125,  ...,  0.9303,  1.0673,  0.4337],\n",
            "         [ 0.2111,  0.1597,  0.5193,  ...,  1.1872,  1.2899, -0.1828],\n",
            "         [ 0.2453,  0.1426,  0.2796,  ...,  1.6324,  1.2557,  0.2282],\n",
            "         ...,\n",
            "         [ 1.0673,  0.3138,  0.6906,  ...,  0.8276,  0.7762,  0.5707],\n",
            "         [ 1.7865,  0.4679,  0.5878,  ...,  0.4851,  0.5536,  0.6563],\n",
            "         [ 1.2214,  0.8447,  1.1700,  ...,  0.6221,  0.6392,  0.6049]],\n",
            "\n",
            "        [[-0.8627, -0.1800,  1.1155,  ...,  0.3452,  0.5028, -0.1800],\n",
            "         [-0.7402, -0.8277, -0.2500,  ...,  0.7304,  0.6954, -0.9678],\n",
            "         [-0.5826, -0.8803, -0.5826,  ...,  1.3256,  0.7479, -0.4951],\n",
            "         ...,\n",
            "         [ 0.5903, -0.3375, -0.0924,  ...,  0.0126, -0.0049, -0.2325],\n",
            "         [ 1.5182, -0.0574, -0.1275,  ..., -0.3550, -0.3375, -0.2325],\n",
            "         [ 0.8704,  0.3452,  0.5903,  ..., -0.2325, -0.1800, -0.2325]],\n",
            "\n",
            "        [[ 0.1302,  0.5485,  1.6465,  ...,  1.0191,  1.4374,  0.7751],\n",
            "         [ 0.2522,  0.0779,  0.4265,  ...,  1.0888,  1.3154,  0.0431],\n",
            "         [ 0.4614,  0.2173,  0.2348,  ...,  2.0125,  1.6640,  0.1651],\n",
            "         ...,\n",
            "         [ 1.2980,  0.5834,  0.6705,  ...,  0.8622,  0.7751,  0.5834],\n",
            "         [ 2.1171,  0.6531,  0.7576,  ...,  0.5659,  0.6531,  0.8099],\n",
            "         [ 1.5071,  0.9494,  1.4722,  ...,  0.6182,  0.7054,  0.7402]]]), tensor(3), tensor([ 1, 10,  1,  0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for idx in range(len(train_data)):\n",
        "  # transformed_val_data.append(train_data[idx])"
      ],
      "metadata": {
        "id": "meayDFyPD72P"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(transformed_val_data))"
      ],
      "metadata": {
        "id": "i-er1YtCENPh"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "outputs": [],
      "source": [
        "resnet18_pretrained = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LK3oDNJaWnPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_epochs = 5"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "snTWKT8NWnPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "outputs": [],
      "source": [
        "resnet18_pretrained.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
        "resnet18_pretrained.load_state_dict(torch.load(\"resnet18_pretrained_all_grad.pt\"))\n",
        "resnet18_pretrained.to(device)\n",
        "def remove_classification_head(model):\n",
        "    modules = list(model.children())[:-1]\n",
        "    model = nn.Sequential(*modules)\n",
        "    return model\n",
        "\n",
        "resnet18_pretrained = remove_classification_head(resnet18_pretrained)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZyzoVoLdWnPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,iid_dataset, ood_dataset=None):\n",
        "        self.data = iid_dataset\n",
        "        self.ood_data = ood_dataset\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = random.choice(self.data)\n",
        "\n",
        "        #We need to approximately 50% of images to be in the same class\n",
        "        should_get_same_class = random.randint(0,1) \n",
        "        if should_get_same_class == 1:\n",
        "            while True:\n",
        "                #Look untill the same class image is found\n",
        "                img1_tuple = random.choice(self.data) \n",
        "                if img0_tuple[1] == img1_tuple[1]:\n",
        "                    break\n",
        "        else:\n",
        "            should_get_ood = 1\n",
        "            if should_get_ood == 1 and self.ood_data is not None:\n",
        "                while True:\n",
        "                    #Look untill a different class image is found\n",
        "                    img1_tuple = random.choice(self.ood_data)\n",
        "                    if img0_tuple[1] != img1_tuple[1]:\n",
        "                        break\n",
        "            else:\n",
        "                while True:\n",
        "                    #Look untill a different class image is found\n",
        "                    img1_tuple = random.choice(self.data)\n",
        "                    if img0_tuple[1] != img1_tuple[1]:\n",
        "                        break\n",
        "\n",
        "        img0 = img0_tuple[0]\n",
        "        img1 = img1_tuple[0]\n",
        "        \n",
        "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "kcIDiIYgVqm9"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "outputs": [],
      "source": [
        "import random"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Y8DYeBZxWnPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SiameseNetworkDataset(train_data, transformed_val_data)\n",
        "id_val_dataset = SiameseNetworkDataset(id_val_data)\n",
        "val_dataset = SiameseNetworkDataset(val_data)"
      ],
      "metadata": {
        "id": "29wbM5M6W0kg"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SiameseNetworkDataset(test_data)"
      ],
      "metadata": {
        "id": "MzFfVZYbIqAc"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the Siamese Neural Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.embed = resnet18_pretrained\n",
        "\n",
        "        # Setting up the Fully Connected Layers\n",
        "        self.fc1 = nn.Sequential(            \n",
        "            nn.Linear(512,2)\n",
        "        )\n",
        "        \n",
        "    def forward_once(self, x):\n",
        "        # This function will be called for both images\n",
        "        # Its output is used to determine the similiarity\n",
        "        output = self.embed(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # In this function we pass in both images and obtain both vectors\n",
        "        # which are returned\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "bUl6UWjlsZPY"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Contrastive Loss Function\n",
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "      # Calculate the euclidean distance and calculate the contrastive loss\n",
        "      euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "\n",
        "      loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "      return loss_contrastive"
      ],
      "metadata": {
        "id": "SF8tlRiRu87k"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,\n",
        "                        shuffle=True,\n",
        "                        batch_size=BATCH_SIZE)\n",
        "\n",
        "id_val_loader = DataLoader(id_val_dataset,\n",
        "                        batch_size=BATCH_SIZE)\n",
        "\n",
        "net = SiameseNetwork().to(device)\n",
        "\n",
        "loss_criterion = ContrastiveLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "WrrwT7zsvFIr"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_dataloader, loss_crt, optimizer, device):\n",
        "    \"\"\"\n",
        "    model: Model object\n",
        "    train_dataloader: DataLoader over the training dataset\n",
        "    loss_crt: loss function object\n",
        "    optimizer: Optimizer object\n",
        "    device: torch.device('cpu) or torch.device('cuda')\n",
        "\n",
        "    The function returns:\n",
        "     - the epoch training loss, which is an average over the individual batch\n",
        "       losses\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    num_batches = len(train_dataloader)\n",
        "    # Iterate over batches\n",
        "    for i, (img0, img1, label) in tqdm(enumerate(train_dataloader, 0)):\n",
        "\n",
        "        # Send the images and labels to CUDA\n",
        "        img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Pass in the two images into the network and obtain two outputs\n",
        "        output1, output2 = model(img0, img1)\n",
        "\n",
        "        # Pass the outputs of the networks and label into the loss function\n",
        "        loss_contrastive = loss_crt(output1, output2, label)\n",
        "\n",
        "        epoch_loss += loss_contrastive.item()\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_contrastive.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    epoch_loss = epoch_loss/num_batches\n",
        "    return epoch_loss\n",
        "\n",
        "def eval_epoch(model, val_dataloader, loss_crt, device):\n",
        "    \"\"\"\n",
        "    model: Model object\n",
        "    val_dataloader: DataLoader over the validation dataset\n",
        "    loss_crt: loss function object\n",
        "    device: torch.device('cpu) or torch.device('cuda')\n",
        "\n",
        "    The function returns:\n",
        "     - the epoch validation loss, which is an average over the individual batch\n",
        "       losses\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    num_batches = len(val_dataloader)\n",
        "    with torch.no_grad():\n",
        "      # Iterate over batches\n",
        "      for i, (img0, img1, label) in tqdm(enumerate(val_dataloader, 0)):\n",
        "\n",
        "          # Send the images and labels to CUDA\n",
        "          img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
        "\n",
        "          # Pass in the two images into the network and obtain two outputs\n",
        "          output1, output2 = model(img0, img1)\n",
        "\n",
        "          # Pass the outputs of the networks and label into the loss function\n",
        "          loss_contrastive = loss_crt(output1, output2, label)\n",
        "\n",
        "          epoch_loss += loss_contrastive.item()\n",
        "\n",
        "    epoch_loss = epoch_loss/num_batches\n",
        "  \n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "ku6KqKdRtIRI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "id_val_losses = []\n",
        "id_val_accuracies = []\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  train_loss = train_epoch(net, train_loader, loss_criterion, optimizer, device)\n",
        "  val_loss = eval_epoch(net, id_val_loader, loss_criterion, device)\n",
        "  train_losses.append(train_loss)\n",
        "  id_val_losses.append(val_loss)\n",
        "  print('\\nEpoch %d'%(epoch))\n",
        "  print('train loss: %10.8f'%(train_loss))\n",
        "  print('id_val loss: %10.8f'%(val_loss))"
      ],
      "metadata": {
        "id": "dLwPgDEmuZdl",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16635a0-be5d-4f02-afe0-5eb9d47520a5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [11:07,  4.67it/s]\n",
            "347it [01:25,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "train loss: 0.18511250\n",
            "id_val loss: 1.80241119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [09:46,  5.31it/s]\n",
            "347it [01:11,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "train loss: 0.09901252\n",
            "id_val loss: 1.62022801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [09:21,  5.55it/s]\n",
            "347it [01:11,  4.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "train loss: 0.04757090\n",
            "id_val loss: 1.93424508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [09:10,  5.67it/s]\n",
            "347it [01:09,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "train loss: 0.04809250\n",
            "id_val loss: 1.76319959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [09:10,  5.67it/s]\n",
            "347it [01:11,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "train loss: 0.02786437\n",
            "id_val loss: 1.81552285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ZlKH0PnkAlch",
        "pycharm": {
          "is_executing": true
        }
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from matplotlib.pyplot import imshow\n",
        "import torchvision.utils\n",
        "# Grab one image that we are going to test\n",
        "dataiter = iter(train_loader)\n",
        "x0, _, label1 = next(dataiter)\n",
        "dataiter = iter(id_val_loader)\n",
        "\n",
        "dissimilarity = [[], []]\n",
        "\n",
        "for i in range(5):\n",
        "    # Iterate over 5 images and test them with the first image (x0)\n",
        "    _, x1, label2 = next(dataiter)\n",
        "    \n",
        "    output1, output2 = net(x0.cuda(), x1.cuda())\n",
        "\n",
        "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "    \"\"\"\n",
        "    talking on the phone\n",
        "    \"\"\"\n",
        "    for idx in range(BATCH_SIZE):\n",
        "      # print(label1[idx].item(), label2[idx].item())\n",
        "      # print(f'Dissimilarity: {euclidean_distance[idx].item():.2f}')\n",
        "      # print(\"\\n\")\n",
        "      dissimilarity[1 if label1[idx].item() == label2[idx].item() else 0].append(euclidean_distance[idx].item())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1CU1STLi2ihG",
        "pycharm": {
          "is_executing": true
        }
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def calc_mean_std(arr):\n",
        "    arr = np.asarray(arr)\n",
        "    return arr.mean(), arr.std()\n",
        "\n",
        "\n",
        "print(calc_mean_std(dissimilarity[0]))\n",
        "print(calc_mean_std(dissimilarity[1]))"
      ],
      "metadata": {
        "id": "2rJXz1yIBgH8",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3ff620-1e2c-4f0a-8097-ac31afab8de3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.10195220599847811, 0.08368997196062244)\n",
            "(0.10382272435287368, 0.07654692009587087)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dissimilarity = [[], []]\n",
        "dataiter = iter(val_loader)\n",
        "for i in range(5):\n",
        "    # Iterate over 5 images and test them with the first image (x0)\n",
        "    _, x1, label2 = next(dataiter)\n",
        "    \n",
        "    output1, output2 = net(x0.cuda(), x1.cuda())\n",
        "\n",
        "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "  \n",
        "    for idx in range(BATCH_SIZE):\n",
        "      # print(label1[idx].item(), label2[idx].item())\n",
        "      # print(f'Dissimilarity: {euclidean_distance[idx].item():.2f}')\n",
        "      dissimilarity[1 if label1[idx].item() == label2[idx].item() else 0].append(euclidean_distance[idx].item())"
      ],
      "metadata": {
        "id": "9ROkdNBaBvmN",
        "pycharm": {
          "is_executing": true
        }
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_mean_std(dissimilarity[0]))\n",
        "print(calc_mean_std(dissimilarity[1]))"
      ],
      "metadata": {
        "id": "RnJbuUF6B35P",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8f47e5-fdce-42a5-e320-5012ca73d894"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.606208580991496, 0.5829712782028255)\n",
            "(1.5370301122174543, 0.6248383777325054)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset,\n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "DDucR0yAIwrI",
        "pycharm": {
          "is_executing": true
        }
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dissimilarity = [[], []]\n",
        "dataiter = iter(test_loader)\n",
        "for i in range(5):\n",
        "    # Iterate over 5 images and test them with the first image (x0)\n",
        "    _, x1, label2 = next(dataiter)\n",
        "    \n",
        "    output1, output2 = net(x0.cuda(), x1.cuda())\n",
        "\n",
        "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "    \n",
        "    for idx in range(BATCH_SIZE):\n",
        "      # print(label1[idx].item(), label2[idx].item())\n",
        "      # print(f'Dissimilarity: {euclidean_distance[idx].item():.2f}')\n",
        "      dissimilarity[1 if label1[idx].item() == label2[idx].item() else 0].append(euclidean_distance[idx].item())"
      ],
      "metadata": {
        "id": "FJT8YCjMIkyT",
        "pycharm": {
          "is_executing": true
        }
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "TODO: SAVE THE MODEL\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pY35HFfMOCCM",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71634a46-d7bd-4e5c-8ca8-c0cecf0ed87d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nTODO: SAVE THE MODEL\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_mean_std(dissimilarity[0]))\n",
        "print(calc_mean_std(dissimilarity[1]))"
      ],
      "metadata": {
        "id": "uUSjfYwGInZf",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a291f43-6448-4000-dea3-6159ef0a57c4"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.20355521790851425, 0.11737141230295087)\n",
            "(0.1575345179563473, 0.11288933166877935)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"contrastive_resnet18_adam.pt\")"
      ],
      "metadata": {
        "id": "SX0HL_d2zhaZ"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = get_train_loader(\"standard\", train_data, batch_size=BATCH_SIZE)\n",
        "id_val_loader = get_train_loader(\"standard\", id_val_data, batch_size=BATCH_SIZE)\n",
        "test_loader = get_train_loader(\"standard\", test_data, batch_size=BATCH_SIZE)\n",
        "\n"
      ],
      "metadata": {
        "id": "HSnqHHcN1vPW"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1, label1, _ = next(iter(id_val_loader))\n",
        "\n",
        "net.eval()\n",
        "dissimilarity = [[], []]\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in tqdm(enumerate(train_loader)):\n",
        "        # Iterate over 5 images and test them with the first image (x0)\n",
        "        x1, label2, _ = batch\n",
        "        \n",
        "        output1, output2 = net(x0.cuda(), x1.cuda())\n",
        "        try:\n",
        "            euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "            \n",
        "            for idx in range(BATCH_SIZE):\n",
        "            # print(label1[idx].item(), label2[idx].item())\n",
        "            # print(f'Dissimilarity: {euclidean_distance[idx].item():.2f}')\n",
        "                dissimilarity[1 if label1[idx].item() == label2[idx].item() else 0].append(euclidean_distance[idx].item())\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Uo4dB7-5c70",
        "outputId": "20bdfaf5-1c1b-46ba-e168-28d686aefe6b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [05:12,  9.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_mean_std(dissimilarity[0]))\n",
        "print(calc_mean_std(dissimilarity[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3xbpV4v7_xh",
        "outputId": "f6c68a5b-d523-4bdf-cd65-dc5697f90058"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.09867890974763098, 0.07807393506476464)\n",
            "(0.09779296635776634, 0.07629760807766515)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1, label1, _ = next(iter(test_loader))\n",
        "\n",
        "net.eval()\n",
        "dissimilarity = [[], []]\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in tqdm(enumerate(train_loader)):\n",
        "        # Iterate over 5 images and test them with the first image (x0)\n",
        "        x1, label2, _ = batch\n",
        "        \n",
        "        output1, output2 = net(x0.cuda(), x1.cuda())\n",
        "        try:\n",
        "            euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "            \n",
        "            for idx in range(BATCH_SIZE):\n",
        "            # print(label1[idx].item(), label2[idx].item())\n",
        "            # print(f'Dissimilarity: {euclidean_distance[idx].item():.2f}')\n",
        "                dissimilarity[1 if label1[idx].item() == label2[idx].item() else 0].append(euclidean_distance[idx].item())\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr8JHcFY8UrO",
        "outputId": "65bbacda-b31e-4099-9ea6-ef9d77b4c125"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [05:08, 10.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_mean_std(dissimilarity[0]))\n",
        "print(calc_mean_std(dissimilarity[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV38UKJ38Xuw",
        "outputId": "2d981146-d879-4778-8a4a-615260ba21e6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.09837486262146662, 0.0783391900471739)\n",
            "(0.0983063083832786, 0.0756569049434798)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "contrastive_learning_2 _adam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}