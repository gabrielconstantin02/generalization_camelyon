{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from wilds.common.data_loaders import get_eval_loader\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the full dataset, and download it if necessary\n",
    "dataset = get_dataset(dataset=\"camelyon17\", download=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# Train loop\\nfor labeled_batch, unlabeled_batch in zip(train_loader, unlabeled_loader):\\n    x, y, metadata = labeled_batch\\n    unlabeled_x, unlabeled_metadata = unlabeled_batch\\n    ...\\n'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the training set\n",
    "train_data = dataset.get_subset(\n",
    "    \"train\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((224, 224)),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Prepare the standard data loader\n",
    "train_loader = get_train_loader(\"standard\", train_data, batch_size=16)\n",
    "\n",
    "\"\"\"\n",
    "# (Optional) Load unlabeled data\n",
    "dataset = get_dataset(dataset=\"camelyon17\", download=True, unlabeled=True)\n",
    "unlabeled_data = dataset.get_subset(\n",
    "    \"test_unlabeled\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "unlabeled_loader = get_train_loader(\"standard\", unlabeled_data, batch_size=16)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Train loop\n",
    "for labeled_batch, unlabeled_batch in zip(train_loader, unlabeled_loader):\n",
    "    x, y, metadata = labeled_batch\n",
    "    unlabeled_x, unlabeled_metadata = unlabeled_batch\n",
    "    ...\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the test set\n",
    "id_val_data = dataset.get_subset(\n",
    "    \"id_val\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((224, 224)),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Prepare the evaluation data loader\n",
    "id_val_loader = get_eval_loader(\"standard\", id_val_data, batch_size=16)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2098\n",
      "18903\n"
     ]
    }
   ],
   "source": [
    "print(len(id_val_loader))\n",
    "print(len(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Get predictions for the full test set\n",
    "for x, y_true, metadata in test_loader:\n",
    "    y_pred = model(x)\n",
    "    # Accumulate y_true, y_pred, metadata\n",
    "\n",
    "# Evaluate\n",
    "dataset.eval(all_y_pred, all_y_true, all_metadata)\n",
    "# {'recall_macro_all': 0.66, ...}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's parameters: \n",
      "\t conv1.weight :  torch.Size([64, 3, 7, 7])\n",
      "\t bn1.weight :  torch.Size([64])\n",
      "\t bn1.bias :  torch.Size([64])\n",
      "\t layer1.0.conv1.weight :  torch.Size([64, 64, 3, 3])\n",
      "\t layer1.0.bn1.weight :  torch.Size([64])\n",
      "\t layer1.0.bn1.bias :  torch.Size([64])\n",
      "\t layer1.0.conv2.weight :  torch.Size([64, 64, 3, 3])\n",
      "\t layer1.0.bn2.weight :  torch.Size([64])\n",
      "\t layer1.0.bn2.bias :  torch.Size([64])\n",
      "\t layer1.1.conv1.weight :  torch.Size([64, 64, 3, 3])\n",
      "\t layer1.1.bn1.weight :  torch.Size([64])\n",
      "\t layer1.1.bn1.bias :  torch.Size([64])\n",
      "\t layer1.1.conv2.weight :  torch.Size([64, 64, 3, 3])\n",
      "\t layer1.1.bn2.weight :  torch.Size([64])\n",
      "\t layer1.1.bn2.bias :  torch.Size([64])\n",
      "\t layer2.0.conv1.weight :  torch.Size([128, 64, 3, 3])\n",
      "\t layer2.0.bn1.weight :  torch.Size([128])\n",
      "\t layer2.0.bn1.bias :  torch.Size([128])\n",
      "\t layer2.0.conv2.weight :  torch.Size([128, 128, 3, 3])\n",
      "\t layer2.0.bn2.weight :  torch.Size([128])\n",
      "\t layer2.0.bn2.bias :  torch.Size([128])\n",
      "\t layer2.0.downsample.0.weight :  torch.Size([128, 64, 1, 1])\n",
      "\t layer2.0.downsample.1.weight :  torch.Size([128])\n",
      "\t layer2.0.downsample.1.bias :  torch.Size([128])\n",
      "\t layer2.1.conv1.weight :  torch.Size([128, 128, 3, 3])\n",
      "\t layer2.1.bn1.weight :  torch.Size([128])\n",
      "\t layer2.1.bn1.bias :  torch.Size([128])\n",
      "\t layer2.1.conv2.weight :  torch.Size([128, 128, 3, 3])\n",
      "\t layer2.1.bn2.weight :  torch.Size([128])\n",
      "\t layer2.1.bn2.bias :  torch.Size([128])\n",
      "\t layer3.0.conv1.weight :  torch.Size([256, 128, 3, 3])\n",
      "\t layer3.0.bn1.weight :  torch.Size([256])\n",
      "\t layer3.0.bn1.bias :  torch.Size([256])\n",
      "\t layer3.0.conv2.weight :  torch.Size([256, 256, 3, 3])\n",
      "\t layer3.0.bn2.weight :  torch.Size([256])\n",
      "\t layer3.0.bn2.bias :  torch.Size([256])\n",
      "\t layer3.0.downsample.0.weight :  torch.Size([256, 128, 1, 1])\n",
      "\t layer3.0.downsample.1.weight :  torch.Size([256])\n",
      "\t layer3.0.downsample.1.bias :  torch.Size([256])\n",
      "\t layer3.1.conv1.weight :  torch.Size([256, 256, 3, 3])\n",
      "\t layer3.1.bn1.weight :  torch.Size([256])\n",
      "\t layer3.1.bn1.bias :  torch.Size([256])\n",
      "\t layer3.1.conv2.weight :  torch.Size([256, 256, 3, 3])\n",
      "\t layer3.1.bn2.weight :  torch.Size([256])\n",
      "\t layer3.1.bn2.bias :  torch.Size([256])\n",
      "\t layer4.0.conv1.weight :  torch.Size([512, 256, 3, 3])\n",
      "\t layer4.0.bn1.weight :  torch.Size([512])\n",
      "\t layer4.0.bn1.bias :  torch.Size([512])\n",
      "\t layer4.0.conv2.weight :  torch.Size([512, 512, 3, 3])\n",
      "\t layer4.0.bn2.weight :  torch.Size([512])\n",
      "\t layer4.0.bn2.bias :  torch.Size([512])\n",
      "\t layer4.0.downsample.0.weight :  torch.Size([512, 256, 1, 1])\n",
      "\t layer4.0.downsample.1.weight :  torch.Size([512])\n",
      "\t layer4.0.downsample.1.bias :  torch.Size([512])\n",
      "\t layer4.1.conv1.weight :  torch.Size([512, 512, 3, 3])\n",
      "\t layer4.1.bn1.weight :  torch.Size([512])\n",
      "\t layer4.1.bn1.bias :  torch.Size([512])\n",
      "\t layer4.1.conv2.weight :  torch.Size([512, 512, 3, 3])\n",
      "\t layer4.1.bn2.weight :  torch.Size([512])\n",
      "\t layer4.1.bn2.bias :  torch.Size([512])\n",
      "\t fc.weight :  torch.Size([1000, 512])\n",
      "\t fc.bias :  torch.Size([1000])\n",
      "Number of model parameters:  11689512\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nyou can use this formula [(W−K+2P)/S]+1.\\n\\nW is the input volume\\nK is the Kernel size\\nP is the padding\\nS is the stride\\n\\n'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load the ResNet-18 model, with randomly initialized weights\n",
    "resnet18_random = models.resnet18(pretrained=False)\n",
    "# load the ResNet-18 model, with weights pretrained on ImageNet\n",
    "resnet18_pretrained = models.resnet18(pretrained=True)\n",
    "\n",
    "num_params = 0\n",
    "print(\"Model's parameters: \")\n",
    "for n, p in resnet18_pretrained.named_parameters():\n",
    "    print('\\t', n, ': ', p.size())\n",
    "    num_params += p.numel()\n",
    "print(\"Number of model parameters: \", num_params)\n",
    "\n",
    "\"\"\"\n",
    "you can use this formula [(W−K+2P)/S]+1.\n",
    "\n",
    "W is the input volume\n",
    "K is the Kernel size\n",
    "P is the padding\n",
    "S is the stride\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# function counting the number of parameters and the number of trainable parameters of a model\n",
    "# optionally, it will also display the layers\n",
    "def check_model_parameters(model, display_layers=False):\n",
    "  num_params = 0\n",
    "  num_trainable_params = 0\n",
    "  if display_layers==True:\n",
    "    print(\"Model's parameters: \")\n",
    "  for n, p in model.named_parameters():\n",
    "      if display_layers == True:\n",
    "        print('\\t', n, ': ', p.size())\n",
    "      num_params += p.numel()\n",
    "      if p.requires_grad:\n",
    "        num_trainable_params += p.numel()\n",
    "  print(\"Number of model parameters: \", num_params)\n",
    "  print(\"Number of trainable parameters: \", num_trainable_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters:  11689512\n",
      "Number of trainable parameters:  11689512\n",
      "Number of model parameters:  11689512\n",
      "Number of trainable parameters:  0\n"
     ]
    }
   ],
   "source": [
    "# freeze the model parameters\n",
    "import torchvision.models as models\n",
    "# load the ResNet-18 model, with weights pretrained on ImageNet\n",
    "resnet18_pretrained = models.resnet18(pretrained=True)\n",
    "\n",
    "# check the number of parameters and the number of trainable parameters\n",
    "check_model_parameters(resnet18_pretrained, display_layers=False)\n",
    "\n",
    "# freeze all the layers\n",
    "for param in resnet18_pretrained.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "# check the number of parameters and the number of trainable parameters\n",
    "check_model_parameters(resnet18_pretrained, display_layers=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's parameters: \n",
      "\t conv1.weight :  torch.Size([64, 3, 7, 7])\n",
      "\t bn1.weight :  torch.Size([64])\n",
      "\t bn1.bias :  torch.Size([64])\n",
      "\t layer1.0.conv1.weight :  torch.Size([64, 64, 3, 3])\n",
      "\t layer1.0.bn1.weight :  torch.Size([64])\n",
      "\t layer1.0.bn1.bias :  torch.Size([64])\n",
      "\t layer1.0.conv2.weight :  torch.Size([64, 64, 3, 3])\n",
      "\t layer1.0.bn2.weight :  torch.Size([64])\n",
      "\t layer1.0.bn2.bias :  torch.Size([64])\n",
      "\t layer1.1.conv1.weight :  torch.Size([64, 64, 3, 3])\n",
      "\t layer1.1.bn1.weight :  torch.Size([64])\n",
      "\t layer1.1.bn1.bias :  torch.Size([64])\n",
      "\t layer1.1.conv2.weight :  torch.Size([64, 64, 3, 3])\n",
      "\t layer1.1.bn2.weight :  torch.Size([64])\n",
      "\t layer1.1.bn2.bias :  torch.Size([64])\n",
      "\t layer2.0.conv1.weight :  torch.Size([128, 64, 3, 3])\n",
      "\t layer2.0.bn1.weight :  torch.Size([128])\n",
      "\t layer2.0.bn1.bias :  torch.Size([128])\n",
      "\t layer2.0.conv2.weight :  torch.Size([128, 128, 3, 3])\n",
      "\t layer2.0.bn2.weight :  torch.Size([128])\n",
      "\t layer2.0.bn2.bias :  torch.Size([128])\n",
      "\t layer2.0.downsample.0.weight :  torch.Size([128, 64, 1, 1])\n",
      "\t layer2.0.downsample.1.weight :  torch.Size([128])\n",
      "\t layer2.0.downsample.1.bias :  torch.Size([128])\n",
      "\t layer2.1.conv1.weight :  torch.Size([128, 128, 3, 3])\n",
      "\t layer2.1.bn1.weight :  torch.Size([128])\n",
      "\t layer2.1.bn1.bias :  torch.Size([128])\n",
      "\t layer2.1.conv2.weight :  torch.Size([128, 128, 3, 3])\n",
      "\t layer2.1.bn2.weight :  torch.Size([128])\n",
      "\t layer2.1.bn2.bias :  torch.Size([128])\n",
      "\t layer3.0.conv1.weight :  torch.Size([256, 128, 3, 3])\n",
      "\t layer3.0.bn1.weight :  torch.Size([256])\n",
      "\t layer3.0.bn1.bias :  torch.Size([256])\n",
      "\t layer3.0.conv2.weight :  torch.Size([256, 256, 3, 3])\n",
      "\t layer3.0.bn2.weight :  torch.Size([256])\n",
      "\t layer3.0.bn2.bias :  torch.Size([256])\n",
      "\t layer3.0.downsample.0.weight :  torch.Size([256, 128, 1, 1])\n",
      "\t layer3.0.downsample.1.weight :  torch.Size([256])\n",
      "\t layer3.0.downsample.1.bias :  torch.Size([256])\n",
      "\t layer3.1.conv1.weight :  torch.Size([256, 256, 3, 3])\n",
      "\t layer3.1.bn1.weight :  torch.Size([256])\n",
      "\t layer3.1.bn1.bias :  torch.Size([256])\n",
      "\t layer3.1.conv2.weight :  torch.Size([256, 256, 3, 3])\n",
      "\t layer3.1.bn2.weight :  torch.Size([256])\n",
      "\t layer3.1.bn2.bias :  torch.Size([256])\n",
      "\t layer4.0.conv1.weight :  torch.Size([512, 256, 3, 3])\n",
      "\t layer4.0.bn1.weight :  torch.Size([512])\n",
      "\t layer4.0.bn1.bias :  torch.Size([512])\n",
      "\t layer4.0.conv2.weight :  torch.Size([512, 512, 3, 3])\n",
      "\t layer4.0.bn2.weight :  torch.Size([512])\n",
      "\t layer4.0.bn2.bias :  torch.Size([512])\n",
      "\t layer4.0.downsample.0.weight :  torch.Size([512, 256, 1, 1])\n",
      "\t layer4.0.downsample.1.weight :  torch.Size([512])\n",
      "\t layer4.0.downsample.1.bias :  torch.Size([512])\n",
      "\t layer4.1.conv1.weight :  torch.Size([512, 512, 3, 3])\n",
      "\t layer4.1.bn1.weight :  torch.Size([512])\n",
      "\t layer4.1.bn1.bias :  torch.Size([512])\n",
      "\t layer4.1.conv2.weight :  torch.Size([512, 512, 3, 3])\n",
      "\t layer4.1.bn2.weight :  torch.Size([512])\n",
      "\t layer4.1.bn2.bias :  torch.Size([512])\n",
      "\t fc.weight :  torch.Size([2, 512])\n",
      "\t fc.bias :  torch.Size([2])\n",
      "Number of model parameters:  11177538\n",
      "Number of trainable parameters:  1026\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet18_pretrained.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "check_model_parameters(resnet18_pretrained, display_layers=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, loss_crt, optimizer, device):\n",
    "    \"\"\"\n",
    "    model: Model object\n",
    "    train_dataloader: DataLoader over the training dataset\n",
    "    loss_crt: loss function object\n",
    "    optimizer: Optimizer object\n",
    "    device: torch.device('cpu) or torch.device('cuda')\n",
    "\n",
    "    The function returns:\n",
    "     - the epoch training loss, which is an average over the individual batch\n",
    "       losses\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    num_batches = len(train_dataloader)\n",
    "    for batch_idx, batch in tqdm(enumerate(train_dataloader)):\n",
    "        # shape: batch_size x 1 x 28 x 28, batch_size x 1\n",
    "        # print(\"Train\")\n",
    "        # print(batch)\n",
    "        batch_img, batch_labels, _ = batch\n",
    "        # move data to GPU\n",
    "        batch_img = batch_img.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        # initialize as zeros all the gradients of the model\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get predictions from the FORWARD pass\n",
    "        # shape: batch_size x 10\n",
    "        output = model(batch_img)\n",
    "\n",
    "        loss = loss_crt(output, batch_labels.squeeze())\n",
    "        loss_scalar = loss.item()\n",
    "\n",
    "        # BACKPROPAGATE the gradients\n",
    "        loss.backward()\n",
    "        # use the gradients to OPTIMISE the model\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss_scalar\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        epoch_accuracy += pred.eq(batch_labels.view_as(pred)).float().mean().item()\n",
    "\n",
    "    epoch_loss = epoch_loss/num_batches\n",
    "    epoch_accuracy = 100. * epoch_accuracy/num_batches\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def eval_epoch(model, val_dataloader, loss_crt, device):\n",
    "    \"\"\"\n",
    "    model: Model object\n",
    "    val_dataloader: DataLoader over the validation dataset\n",
    "    loss_crt: loss function object\n",
    "    device: torch.device('cpu) or torch.device('cuda')\n",
    "\n",
    "    The function returns:\n",
    "     - the epoch validation loss, which is an average over the individual batch\n",
    "       losses\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    num_batches = len(val_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in tqdm(enumerate(val_dataloader)):\n",
    "            # print(\"Eval\")\n",
    "            # print(batch)\n",
    "            # shape: batch_size x 3 x 28 x 28, batch_size x 1\n",
    "            batch_img, batch_labels, _ = batch\n",
    "            current_batch_size = batch_img.size(0)\n",
    "\n",
    "            # move data to GPU\n",
    "            batch_img = batch_img.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # batch_size x 10\n",
    "            output = model(batch_img)\n",
    "\n",
    "            loss = loss_crt(output, batch_labels.squeeze())\n",
    "            loss_scalar = loss.item()\n",
    "\n",
    "            epoch_loss += loss_scalar\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            epoch_accuracy += pred.eq(batch_labels.view_as(pred)).float().mean().item()\n",
    "\n",
    "    epoch_loss = epoch_loss/num_batches\n",
    "    epoch_accuracy = 100. * epoch_accuracy/num_batches\n",
    "    return epoch_loss, epoch_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14525it [1:30:54,  3.79it/s]"
     ]
    }
   ],
   "source": [
    "resnet18_pretrained.to(device)\n",
    "\n",
    "# create a SGD optimizer\n",
    "optimizer = torch.optim.SGD(resnet18_pretrained.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# set up loss function\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# evaluate the initial model\n",
    "# val_loss, al_accuracy = eval_epoch(resnet18_pretrained, id_val_loader, loss_criterion, device)\n",
    "# print('Validation performance before finetuning -- loss: %10.8f, accuracy: %10.8f'%(val_loss, val_accuracy))\n",
    "\n",
    "# finetune the model\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  train_loss, train_accuracy = train_epoch(resnet18_pretrained, train_loader, loss_criterion, optimizer, device)\n",
    "  val_loss, val_accuracy = eval_epoch(resnet18_pretrained, id_val_loader, loss_criterion, device)\n",
    "  train_losses.append(train_loss)\n",
    "  val_losses.append(val_loss)\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  val_accuracies.append(val_accuracy)\n",
    "  print('\\nEpoch %d'%(epoch))\n",
    "  print('train loss: %10.8f, accuracy: %10.8f'%(train_loss, train_accuracy))\n",
    "  print('val loss: %10.8f, accuracy: %10.8f'%(val_loss, val_accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "densenet121_pretrained = models.densenet121(pretrained=True)\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  train_loss, train_accuracy = train_epoch(densenet121_pretrained, train_loader, loss_criterion, optimizer, device)\n",
    "  val_loss, val_accuracy = eval_epoch(densenet121_pretrained, id_val_loader, loss_criterion, device)\n",
    "  train_losses.append(train_loss)\n",
    "  val_losses.append(val_loss)\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  val_accuracies.append(val_accuracy)\n",
    "  print('\\nEpoch %d'%(epoch))\n",
    "  print('train loss: %10.8f, accuracy: %10.8f'%(train_loss, train_accuracy))\n",
    "  print('val loss: %10.8f, accuracy: %10.8f'%(val_loss, val_accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}