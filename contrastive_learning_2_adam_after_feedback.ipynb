{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "iwSgBXS4WnPJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "231c0d3d-8b1f-4c8b-fb95-436b18cecd3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 126 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Collecting pytz>=2020.4\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 41.5 MB/s \n",
            "\u001b[?25hCollecting pillow>=7.2.0\n",
            "  Downloading Pillow-9.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 32.4 MB/s \n",
            "\u001b[?25hCollecting ogb>=1.2.6\n",
            "  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.21.5)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from wilds) (0.11.1+cu111)\n",
            "Collecting scipy>=1.5.4\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.3.5)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.2.6->wilds) (1.24.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.2.6->wilds) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->wilds) (2.23.0)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->wilds) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->wilds) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->wilds) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (2021.10.8)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=485fdca168659b87da49ff0b6a8f772c55ae32cf0b5adda6cd3431eaf8b0a9b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: scipy, pytz, littleutils, pillow, outdated, ogb, wilds\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.3 outdated-0.2.1 pillow-9.1.0 pytz-2022.1 scipy-1.7.3 wilds-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# !pip install wilds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from wilds import get_dataset\n",
        "from wilds.common.data_loaders import get_train_loader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from wilds.common.data_loaders import get_eval_loader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fbFdMbP_WnPK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "outputs": [],
      "source": [
        "# Load the full dataset, and download it if necessary\n",
        "dataset = get_dataset(dataset=\"camelyon17\", download=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bAbxogzDWnPL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99804\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Train loop\\nfor labeled_batch, unlabeled_batch in zip(train_loader, unlabeled_loader):\\n    x, y, metadata = labeled_batch\\n    unlabeled_x, unlabeled_metadata = unlabeled_batch\\n    ...\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "FRACTION = 0.33\n",
        "\n",
        "# Get the training set\n",
        "train_data = dataset.get_subset(\n",
        "    \"train\",\n",
        "    frac = FRACTION,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(len(train_data)) #302436 initially\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "vkrWsMbmWnPL",
        "outputId": "875a9ab5-5ab1-41cb-dc11-065624b07697"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11075\n"
          ]
        }
      ],
      "source": [
        "# Get the id_val set\n",
        "id_val_data = dataset.get_subset(\n",
        "    \"id_val\",\n",
        "    frac = FRACTION,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(len(id_val_data))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bQG8UEhWnPM",
        "outputId": "eb80d900-1ab2-4298-e6c7-9f85f7d3aeef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11518\n"
          ]
        }
      ],
      "source": [
        "# Get the val set\n",
        "val_data = dataset.get_subset(\n",
        "    \"val\",\n",
        "    frac = FRACTION,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(len(val_data))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84YtJhH4WnPM",
        "outputId": "edd77ded-613b-4519-9246-09c85f504aba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28068\n"
          ]
        }
      ],
      "source": [
        "# Get the test set\n",
        "test_data = dataset.get_subset(\n",
        "    \"test\",\n",
        "    frac = FRACTION,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(len(test_data))\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD1XSgxnWnPN",
        "outputId": "8e244c21-dfb1-4851-a4d4-de6b5628c515"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "outputs": [],
      "source": [
        "resnet18_pretrained = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LK3oDNJaWnPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_epochs = 5"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "snTWKT8NWnPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "outputs": [],
      "source": [
        "resnet18_pretrained.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
        "# resnet18_pretrained.load_state_dict(torch.load(\"resnet18_pretrained_all_grad.pt\"))\n",
        "resnet18_pretrained.to(device)\n",
        "def remove_classification_head(model):\n",
        "    modules = list(model.children())[:-1]\n",
        "    model = nn.Sequential(*modules)\n",
        "    return model\n",
        "\n",
        "resnet18_pretrained = remove_classification_head(resnet18_pretrained)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZyzoVoLdWnPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,iid_dataset, ood_dataset=None):\n",
        "        self.data = iid_dataset\n",
        "        self.ood_data = ood_dataset\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = random.choice(self.data)\n",
        "        \n",
        "        should_get_same_distribution = random.randint(0,1) # 50% chance\n",
        "        if should_get_same_distribution == 1:\n",
        "          img1_tuple = random.choice(self.data) \n",
        "                \n",
        "        else:\n",
        "          img1_tuple = random.choice(self.ood_data)\n",
        "\n",
        "        img0 = img0_tuple[0]\n",
        "        img1 = img1_tuple[0]\n",
        "        \n",
        "        return img0, img1, torch.from_numpy(np.array([should_get_same_distribution], dtype=np.float32))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "kcIDiIYgVqm9"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SiameseNetworkDataset(train_data, val_data)\n",
        "id_val_dataset = SiameseNetworkDataset(id_val_data, val_data)"
      ],
      "metadata": {
        "id": "29wbM5M6W0kg"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the Siamese Neural Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.embed = resnet18_pretrained\n",
        "\n",
        "        # Setting up the Fully Connected Layers\n",
        "        self.fc1 = nn.Sequential(            \n",
        "            nn.Linear(512,2)\n",
        "        )\n",
        "        \n",
        "    def forward_once(self, x):\n",
        "        # This function will be called for both images\n",
        "        # Its output is used to determine the similiarity\n",
        "        output = self.embed(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # In this function we pass in both images and obtain both vectors\n",
        "        # which are returned\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "bUl6UWjlsZPY"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Contrastive Loss Function\n",
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "      # Calculate the euclidean distance and calculate the contrastive loss\n",
        "      euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "\n",
        "      loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "      return loss_contrastive"
      ],
      "metadata": {
        "id": "SF8tlRiRu87k"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,\n",
        "                        shuffle=True,\n",
        "                        batch_size=BATCH_SIZE)\n",
        "\n",
        "id_val_loader = DataLoader(id_val_dataset,\n",
        "                        batch_size=BATCH_SIZE)\n",
        "\n",
        "net = SiameseNetwork().to(device)\n",
        "\n",
        "loss_criterion = ContrastiveLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "WrrwT7zsvFIr"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_dataloader, loss_crt, optimizer, device):\n",
        "    \"\"\"\n",
        "    model: Model object\n",
        "    train_dataloader: DataLoader over the training dataset\n",
        "    loss_crt: loss function object\n",
        "    optimizer: Optimizer object\n",
        "    device: torch.device('cpu) or torch.device('cuda')\n",
        "\n",
        "    The function returns:\n",
        "     - the epoch training loss, which is an average over the individual batch\n",
        "       losses\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    num_batches = len(train_dataloader)\n",
        "    # Iterate over batches\n",
        "    for i, (img0, img1, label) in tqdm(enumerate(train_dataloader, 0)):\n",
        "\n",
        "        # Send the images and labels to CUDA\n",
        "        img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Pass in the two images into the network and obtain two outputs\n",
        "        output1, output2 = model(img0, img1)\n",
        "\n",
        "        # Pass the outputs of the networks and label into the loss function\n",
        "        loss_contrastive = loss_crt(output1, output2, label)\n",
        "\n",
        "        epoch_loss += loss_contrastive.item()\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_contrastive.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    epoch_loss = epoch_loss/num_batches\n",
        "    return epoch_loss\n",
        "\n",
        "def eval_epoch(model, val_dataloader, loss_crt, device):\n",
        "    \"\"\"\n",
        "    model: Model object\n",
        "    val_dataloader: DataLoader over the validation dataset\n",
        "    loss_crt: loss function object\n",
        "    device: torch.device('cpu) or torch.device('cuda')\n",
        "\n",
        "    The function returns:\n",
        "     - the epoch validation loss, which is an average over the individual batch\n",
        "       losses\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    num_batches = len(val_dataloader)\n",
        "    with torch.no_grad():\n",
        "      # Iterate over batches\n",
        "      for i, (img0, img1, label) in tqdm(enumerate(val_dataloader, 0)):\n",
        "\n",
        "          # Send the images and labels to CUDA\n",
        "          img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
        "\n",
        "          # Pass in the two images into the network and obtain two outputs\n",
        "          output1, output2 = model(img0, img1)\n",
        "\n",
        "          # Pass the outputs of the networks and label into the loss function\n",
        "          loss_contrastive = loss_crt(output1, output2, label)\n",
        "\n",
        "          epoch_loss += loss_contrastive.item()\n",
        "\n",
        "    epoch_loss = epoch_loss/num_batches\n",
        "  \n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "ku6KqKdRtIRI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "id_val_losses = []\n",
        "id_val_accuracies = []\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  train_loss = train_epoch(net, train_loader, loss_criterion, optimizer, device)\n",
        "  val_loss = eval_epoch(net, id_val_loader, loss_criterion, device)\n",
        "  train_losses.append(train_loss)\n",
        "  id_val_losses.append(val_loss)\n",
        "  print('\\nEpoch %d'%(epoch))\n",
        "  print('train loss: %10.8f'%(train_loss))\n",
        "  print('id_val loss: %10.8f'%(val_loss))"
      ],
      "metadata": {
        "id": "dLwPgDEmuZdl",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16635a0-be5d-4f02-afe0-5eb9d47520a5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [11:07,  4.67it/s]\n",
            "347it [01:25,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "train loss: 0.18511250\n",
            "id_val loss: 1.80241119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [09:46,  5.31it/s]\n",
            "347it [01:11,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "train loss: 0.09901252\n",
            "id_val loss: 1.62022801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [09:21,  5.55it/s]\n",
            "347it [01:11,  4.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "train loss: 0.04757090\n",
            "id_val loss: 1.93424508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [09:10,  5.67it/s]\n",
            "347it [01:09,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "train loss: 0.04809250\n",
            "id_val loss: 1.76319959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [09:10,  5.67it/s]\n",
            "347it [01:11,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "train loss: 0.02786437\n",
            "id_val loss: 1.81552285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from matplotlib.pyplot import imshow\n",
        "import torchvision.utils\n",
        "# Grab one image that we are going to test\n",
        "dataiter = iter(train_loader)\n",
        "x0, _, label1 = next(dataiter)\n",
        "dataiter = iter(id_val_loader)\n",
        "\n",
        "dissimilarity = [[], []]\n",
        "\n",
        "for i in range(5):\n",
        "    # Iterate over 5 images and test them with the first image (x0)\n",
        "    _, x1, label2 = next(dataiter)\n",
        "    \n",
        "    output1, output2 = net(x0.cuda(), x1.cuda())\n",
        "\n",
        "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "    \"\"\"\n",
        "    talking on the phone\n",
        "    \"\"\"\n",
        "    for idx in range(BATCH_SIZE):\n",
        "      # print(label1[idx].item(), label2[idx].item())\n",
        "      # print(f'Dissimilarity: {euclidean_distance[idx].item():.2f}')\n",
        "      # print(\"\\n\")\n",
        "      dissimilarity[1 if label1[idx].item() == label2[idx].item() else 0].append(euclidean_distance[idx].item())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1CU1STLi2ihG",
        "pycharm": {
          "is_executing": true
        }
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def calc_mean_std(arr):\n",
        "    arr = np.asarray(arr)\n",
        "    return arr.mean(), arr.std()\n",
        "\n",
        "\n",
        "print(calc_mean_std(dissimilarity[0]))\n",
        "print(calc_mean_std(dissimilarity[1]))"
      ],
      "metadata": {
        "id": "2rJXz1yIBgH8",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3ff620-1e2c-4f0a-8097-ac31afab8de3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.10195220599847811, 0.08368997196062244)\n",
            "(0.10382272435287368, 0.07654692009587087)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"contrastive_resnet18_adam.pt\")"
      ],
      "metadata": {
        "id": "SX0HL_d2zhaZ"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = get_train_loader(\"standard\", train_data, batch_size=BATCH_SIZE)\n",
        "id_val_loader = get_train_loader(\"standard\", id_val_data, batch_size=BATCH_SIZE)\n",
        "test_loader = get_train_loader(\"standard\", test_data, batch_size=BATCH_SIZE)\n",
        "\n"
      ],
      "metadata": {
        "id": "HSnqHHcN1vPW"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1, label1, _ = next(iter(id_val_loader))\n",
        "\n",
        "net.eval()\n",
        "dissimilarity = [[], []]\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in tqdm(enumerate(train_loader)):\n",
        "        # Iterate over 5 images and test them with the first image (x0)\n",
        "        x1, label2, _ = batch\n",
        "        \n",
        "        output1, output2 = net(x0.cuda(), x1.cuda())\n",
        "        try:\n",
        "            euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "            \n",
        "            for idx in range(BATCH_SIZE):\n",
        "            # print(label1[idx].item(), label2[idx].item())\n",
        "            # print(f'Dissimilarity: {euclidean_distance[idx].item():.2f}')\n",
        "                dissimilarity[1 if label1[idx].item() == label2[idx].item() else 0].append(euclidean_distance[idx].item())\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Uo4dB7-5c70",
        "outputId": "20bdfaf5-1c1b-46ba-e168-28d686aefe6b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [05:12,  9.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_mean_std(dissimilarity[0]))\n",
        "print(calc_mean_std(dissimilarity[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3xbpV4v7_xh",
        "outputId": "f6c68a5b-d523-4bdf-cd65-dc5697f90058"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.09867890974763098, 0.07807393506476464)\n",
            "(0.09779296635776634, 0.07629760807766515)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1, label1, _ = next(iter(test_loader))\n",
        "\n",
        "net.eval()\n",
        "dissimilarity = [[], []]\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in tqdm(enumerate(train_loader)):\n",
        "        # Iterate over 5 images and test them with the first image (x0)\n",
        "        x1, label2, _ = batch\n",
        "        \n",
        "        output1, output2 = net(x0.cuda(), x1.cuda())\n",
        "        try:\n",
        "            euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "            \n",
        "            for idx in range(BATCH_SIZE):\n",
        "            # print(label1[idx].item(), label2[idx].item())\n",
        "            # print(f'Dissimilarity: {euclidean_distance[idx].item():.2f}')\n",
        "                dissimilarity[1 if label1[idx].item() == label2[idx].item() else 0].append(euclidean_distance[idx].item())\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr8JHcFY8UrO",
        "outputId": "65bbacda-b31e-4099-9ea6-ef9d77b4c125"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3119it [05:08, 10.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_mean_std(dissimilarity[0]))\n",
        "print(calc_mean_std(dissimilarity[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV38UKJ38Xuw",
        "outputId": "2d981146-d879-4778-8a4a-615260ba21e6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.09837486262146662, 0.0783391900471739)\n",
            "(0.0983063083832786, 0.0756569049434798)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "contrastive_learning_2 _adam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}